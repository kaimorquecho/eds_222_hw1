---
title: "EDS 222: Homework 1"
date: 10/14/24
author: Kaiju Morquecho
---

## Background

*(The case study in this exercise is based on reality, but does not include actual observational data.)*

In this exercise we will look at a case study concerning air quality in South Asia. The World Health Organization estimates that air pollution kills an estimated seven million people per year, due to its effects on the cardiovascular and respiratory systems. Out of the 40 most polluted cities in the world, South Asia is home to 37, and Pakistan was ranked to contain the second most air pollution in the world in 2020 (IQAIR, 2020). In 2019, Lahore, Pakistan was the 12th most polluted city in the world, exposing a population of 11.1 million people to increased mortality and morbidity risks.

In this exercise, you are given two datasets from Lahore, Pakistan and are asked to compare the two different data collection strategies from this city. These data are:

-   Crowd-sourced data from air quality monitors located in people's homes. These data are voluntarily collected by individual households who choose to install a monitor in their home and upload their data for public access.

-   Official government data from monitors installed by government officials at selected locations across Lahore. There have been reports that government officials strategically locate monitors in locations with cleaner air in order to mitigate domestic and international pressure to clean up the air.

::: callout-note
All data for EDS 222 will be stored on the Taylor server, in the shared `/courses/eds-222/data/` directory. Please see material from EDS 214 on how to access and retrieve data from Taylor. These data are small; all compute can be handled locally. Thanks to Bren PhD student Fatiq Nadeem for assembling these data!
:::

In answering the following questions, please consider the lecture content from class on sampling strategies, as well as the material in Chapter 2 of [*Introduction to Modern Statistics*](https://openintro-ims.netlify.app/data-design). Include in your submission your version of this file "`eds-222-hw1.qmd`" and the rendered HTML output, each containing complete answers to all questions *as well as the associated code*. Questions with answers unsupported by the code will be marked incomplete. Showing your work this way will help you develop the habit of creating reproducible code.

## Assessment

### Question 1

Load the data from each source and label it as `crowdsourced` and `govt` accordingly. For example:

``` r
crowdsourced <- readRDS(file.path("data", "airpol-PK-crowdsourced.RDS"))
govt <- readRDS(file.path("data", "airpol-PK-govt.RDS"))
```

::: callout-warning
There's an implicit assumption about file organization in the code above. What is it? How can you make the code work? 
:::

The implicit assumption about file organization in the code above is that I will keep my data inside a subfolder called "data"

#### __Code:__

```{r}
# Reading in data
crowdsourced <- readRDS(file.path("data", "airpol-PK-crowdsourced.RDS"))
govt <- readRDS(file.path("data", "airpol-PK-govt.RDS"))

# Checking for NAs
sum(is.na(crowdsourced))
sum(is.na(govt))
```


1.  These dataframes have one row per pollution observation. How many pollution records are in each dataset?

There are 5488 pollution records in crowdsourced and 1960 poluttion records in govt. Using str() I can see summary info of my objects such as the classes, the # of obs, # of variables etc. 

#### __Code:__

```{r}
str(crowdsourced) # str shows me a summary/a preview of the structure of my desired object 
str(govt)
```   


2.  Each monitor is located at a unique latitude and longitude location. How many unique monitors are in each dataset?

There are 14 unique monitors in crowdsourced and 5 in govt

#### __Code:__

```{r}
# load the library "dplyr"
library(dplyr)

# piping to data, grouping by lat & long, create new col = id of each grouping, # of groupings = # of monitors

crowdsourced %>%
  group_by(longitude, latitude) %>% 
  summarize(id = cur_group_id(),
            .groups = "drop") %>% 
  nrow()
```

```{r}
govt %>%
  group_by(longitude, latitude) %>% 
  summarize(id = cur_group_id(),
            .groups = "drop") %>% 
  nrow()
```

::: callout-tip
`group_by(longitude,latitude)` and `cur_group_id()` in `dplyr` will help in creating a unique identifier for each (longitude, latitude) pair.
:::

### Question 2

The goal of pollution monitoring in Lahore is to measure the average pollution conditions across the city.

1.  What is the *population* in this setting? Please be precise.

The population is the city of Lahore, Pakistan.

2.  What are the *samples* in this setting? Please be precise.

There are two samples - One sample are the households in Lahore who have volunteered to install a monitor in their home, and the other is the locations in Lahore that the government has chosen to place monitors at. 

3.  These samples were not randomly collected from across locations in Lahore. Given the sampling approaches described above, discuss possible biases that may enter when we use these samples to construct estimates of population parameters.

The sampling methods introduce several sampling biases. The samples are not be representative of the population. 

- Self-selection bias. The crowdsourced data sample comes from homes who have chosen to participate in monitoring pollution by having a monitor at their home. There may be technological requirements such as access to wifi, a computer, or electricity, or some members of the population may simple be unaware of the fact that data is being gathered and they can participate. Thus, the sample will not be representative of the entire population.

- Exclusion bias. Given that government officials have been observed to place monitors stratigically in "cleaner" areas to obtain more favorable data, significant portions of the population are being excluded. Areas where air is "dirtier" are being excluded from the sample and therefore misrepresenting the population. 

### Question 3

1.  For both the government data and the crowd-sourced data, report the sample mean, sample minimum, and sample maximum value of PM 2.5 (measured in $\mu g/m^3$).

__crowdsourced__:

sample mean = 70.2008 $\mu g/m^3$

min = 20 $\mu g/m^3$

max = 120 $\mu g/m^3$      

__govt__:

sample mean = 39.64694 $\mu g/m^3$

min = 15 $\mu g/m^3$

max = 65 $\mu g/m^3$  

#### __Code:__

```{r}
# crowdsourced mean
#  pipe to df, use summarize function, apply mean() to col "PM"
crowdsourced_mean <- crowdsourced %>%
  summarize(mean(PM), na.rm = TRUE)
```

```{r}
# govt mean
govt_mean <- govt %>% 
  summarize(mean(PM), na.rm = TRUE) 
```

```{r}
# crowdsourced min and max
crowdsourced %>%  
  summarize(min_crowd = min(PM), 
            max_crowd = max(PM)) 
```

```{r}
# govt min and max
govt %>% 
  summarize(min_govt = min(PM), 
            max_govt = max(PM))
```


2.  Discuss any key differences that you see between these two samples.

The crowdsourced data contains far more obs than the govt data, and it's collected using 14 different monitors, as opposed to 5 for govt data.These differences in data gathering are observable in the summary statistics of the samples. The crowdsourced data (min= 20, max=120) has a larger range than govt (min=15, max=65) data, likely because crowdsourced data is composed of more observations and coming from more monitors than the govt data, leading to greater variability. Furthermore,the crowdsourced mean (70.2008) is significantly bigger than that of the govt (39.64694). 

3.  Are the differences in mean pollution as expected, given what we know about the sampling strategies?

Given what we know, the differences in mean pollution are exactly as we expected. Crowdsourced mean (70.2008) is bigger than that of the govt (39.64694) not only for the reasons mentioned above (more observations + more data sources/monitors) but also because of the sampling bias I discussed earlier. The govt data has a tigher range and the values come from monitors strategically placed in locations that government officials believed to be favorable (less polluted, cleaner air), which explains why its mean is smaller and the data less widespread. 

### Question 4

Use the location of the air pollution stations for both of the sampling strategies to generate a map showing locations of each observation. Color the two samples with different colors to highlight how each sample obtains measurements from different parts of the city.


::: callout-tip
`longitude` indicates location in the *x*-direction, while `latitude` indicates location in the *y*-direction. With `ggplot2` this should be nothing fancy. We'll do more spatial data in `R` later in the course.
:::

#### __Code:__

```{r}
# load ggplot library
library(ggplot2)

# use ggplot to make map.
ggplot() +
  geom_point(data= crowdsourced, aes(x= longitude, y= latitude, color = "Crowdsourced")) +
  geom_point(data= govt, aes(x= longitude, y = latitude, color = "Govt" ))+
  ggtitle("Crowdsourced and govt sampling methods in Lahore,Pakistan") +
  scale_color_manual(values = c("Crowdsourced" = "firebrick", "Govt" = "navyblue")) + # having text = color                                                                         # legend is automatically added to plot
  xlab("Longitude(°)") + # rename legend labels
  ylab("Latitude(°)") +
  theme_bw() + # remove default gray bw
  theme(text = element_text(family = 'courier')) + # change font
  theme(legend.title=element_blank()) # remove legend title 
  

```

### Question 5

The local newspaper in Pakistan, *Dawn*, claims that the government is misreporting the air pollution levels in Lahore. Do the locations of monitors in question 4, relative to crowd-sourced monitors, suggest anything about a possible political bias?

Yes, the locations of monitors in Q4 support the Dawn's claims. The distribution of the monitors for the govt sample are clustered together within 74.325 and 74.337° longitude and 31.57° and less than 31.58° latitude. This means the govt sampled a very small, specific area of Lahore, resulting in data that is purposefully under-reporting pollution by being selective in monitor placement. The area may have less pollution / more favorable air conditions because it is a residential, rural, or other-wise non-industrial neighborhood. Regardless of why the area sampled with the monitors had a lower pollution average, the sample is not representative of the population (Lahore, Pakistan) and it could be indicative of political bias. The area could be within a district or town where a seat or position in gov is up for reelection, or simply to upkeep the reputation of that district's administration. Or it could be for international/national political purposes; reporting decent pollution conditions to international authorities or national authorities would mean not having to implement abatement methods, place restrictions on permitted activities or setting caps on pollution, etc.,. 


### Question 6

Given the recent corruption in air quality reporting, the Prime Minister of Pakistan has hired an independent body of environmental data scientists to create an unbiased estimate of the mean PM 2.5 across Lahore using some combination of both government stations and crowd sourced observations.

NASA's satellite data indicates that the average PM across Lahore is 89.2 $\mu g/m^3$. Since this is the most objective estimate of population-level PM 2.5 available, your goal is to match this mean as closely as possible by creating a new ground-level monitoring sample that draws on both the government and crowd-sourced samples.

#### Question 6.1

First, generate a *random sample* of size $n=1000$ air pollution records by (i) pooling observations across the government and the crowd-sourced data; and (ii) drawing observations at random from this pooled sample.

::: callout-tip
`bind_rows()` may be helpful.
:::

#### __Code:__

```{r}
pooled_samples <- bind_rows(crowdsourced, govt) # merging both samples
pooled_1000 <- sample_n(pooled_samples, 1000) # draw random n=1000 sample
```

Second, create a *stratified random sample*. Do so by (i) stratifying your pooled data-set into strata of 0.01 degrees of latitude, and (ii) randomly sampling 200 air pollution observations from each stratum.

#### __Code:__

```{r}

strat_sample <- pooled_samples %>% # stratifying into strata of 0.01 degrees of latitude. 
  mutate(lat_strata = round(latitude, 2)) %>%
  group_by(lat_strata) # note to self: we don't order from min to max before stratifying because we want to take 
                       # a random sample eventually

strat_random_sample <- strat_sample %>% 
  slice_sample(n = 200) # take the random sample of 200 obs from each stratum

# note to self: the sample is still grouped here in line 243 so slice_sample will know to take 200 from each group and it will be random because other than being in strata, our data is randomly ordered / not from min to max

```

#### Question 6.2

Compare estimated means of PM 2.5 for each sampling strategy to the NASA estimate of 89.2 $\mu g/m^3$. Which sample seems to match the satellite data best? What would you recommend the Prime Minister do? Does your proposed sampling strategy rely more on government or on crowd-sourced data? Why might that be the case?

#### __Code:__

```{r}
# calculate the mean for stratified random sample and for the pooled n = 1000 sample since I haa not calculated those 
strat_mean <- strat_random_sample %>%
  ungroup() %>%
  summarize(mean(PM)) %>%
  print()

pooled_1000_mean <- pooled_1000 %>%
  summarize(mean(PM)) %>%
  print()

# print previously calculated mean for the original crowdsourced and govt samples

print(crowdsourced_mean)

print(govt_mean)

```

The crowdsourced sample matches the satelite data best at 70.2  $\mu g/m^3$. This makes sense given that the we know the sample is not purposefully under-reporting pollution conditions and it has not been pooled yet with the govt data, it has not been skewed by misleading obs. 

However, even though it is the closest, it is still biased as discussed earlier. I would recommend to the Prime Minister that govt data be used to calculate the best estimate of $\mu g/m^3$, but with the condition that monitors be distributed all over Lahore, not only where convinient. 

There big issues in relying on govt data due corruption, but there may be strategies that can be implemented to mitigate this risk at a lower cost than the crowdsourcing alternative. I would recommend that a civilian task-force be created to supervise the placement of monitors by govt officials. I'd recommend that the distribution and amount of monitors be proportional to the population size of each district in Lahore. 

While it would be good to gather crowdsourced data, there will always be a concern for self-selection bias unless there be a significant financial investment to subsidize the cost (assuming there is one) for all homes to have a monitor, incentivize others to participate in data gathering,or bridge geographic and technological barriers all across Lahore. 

